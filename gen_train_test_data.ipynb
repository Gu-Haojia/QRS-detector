{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training/Testing Data\n",
    "\n",
    "This notebook will parse through the preprocessed data from preprocess.ipynp and break it into training and testing data sets. The general strategy will be to create windows of length 1 second (125 points), with a sliding length of 10 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pywt\n",
    "import numpy as np\n",
    "from memory_profiler import profile\n",
    "\n",
    "#!pip install googledrivedownloader\n",
    "#from google_drive_downloader import GoogleDriveDownloader as gdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window size is 1 second (256 points)\n",
    "WIN_LEN = 256\n",
    "\n",
    "#amount of points to slide forward for next window\n",
    "WIN_SLIDE = 16\n",
    "\n",
    "#at least 75% of the indices within a given window should be within the valid indices\n",
    "#TODO: is this a good threshold? the lower this number is, it could affect performance quite a bit\n",
    "MIN_VALID_PERC = 0.9\n",
    "\n",
    "#define the frequencies for the cwt\n",
    "wavelet = 'morl'\n",
    "scales = np.arange(2,64)  #this corresponds to ~1.5Hz - 50Hz\n",
    "wavelet_freqs = pywt.scale2frequency(wavelet, scales)*256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the preprocessed data (as generated from preprocess.ipynp). Note that this is ~500MB so it will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the link to download data_labels_preprocessed.pkl\n",
    "#file_id = '1vcBM0UOxoUhUUHTKzNDpRFVq9pn5eA0g'\n",
    "\n",
    "#load in the data and labels\n",
    "#gdd.download_file_from_google_drive(file_id=file_id, dest_path='./data_labels_preprocessed.pkl')\n",
    "#df = pd.read_pickle('data_labels_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to window the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(row, activity):\n",
    "    #record_name = row['record_name']\n",
    "    #print(record_name)\n",
    "\n",
    "    #check if there is no data here\n",
    "    if row[activity] is None: return []\n",
    "\n",
    "    #set up the data and labels\n",
    "    coefficients = row[activity]['cwt']\n",
    "    data = row[activity]['ecg']\n",
    "    N = np.shape(coefficients)[1]\n",
    "    QRS_labels = row[activity]['qrs']\n",
    "    r_labels = row[activity]['rr']\n",
    "    #print(N)\n",
    "    N=min(40000,N)\n",
    "\n",
    "\n",
    "    windows = []\n",
    "    #now loop through windows of length WIN_LEN and generate windows with labels\n",
    "\n",
    "    for i in range(0, N-WIN_LEN, WIN_SLIDE):\n",
    "        #get the current window indices\n",
    "        tmp_inds = range(i,i+WIN_LEN)\n",
    "\n",
    "        #confirm that at least 90% of the points are within the valid indices\n",
    "        #if sum(np.isin(tmp_inds, valid_inds))/WIN_LEN < MIN_VALID_PERC: continue\n",
    "\n",
    "        #grab the data for this window\n",
    "        tmp_win = coefficients[:,tmp_inds]\n",
    "        tmp_labels = QRS_labels[tmp_inds]\n",
    "        tmp_r= r_labels[tmp_inds]\n",
    "        tmp_data = data[tmp_inds]\n",
    "        \"\"\"\n",
    "        #plot\n",
    "        power = (abs(tmp_win))**2\n",
    "        levels = [0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8]\n",
    "        contourlevels = np.log2(levels)\n",
    "        \n",
    "        if i == 5000:\n",
    "            plt.figure(figsize=(10,6))\n",
    "            ax1 = plt.subplot(211)\n",
    "            plt.plot(tmp_labels, 'b', label='Label')\n",
    "            plt.plot(tmp_data, label='ECG')\n",
    "            plt.legend(loc=1)\n",
    "            ax2 = plt.subplot(212, sharex=ax1)\n",
    "            plt.contourf(range(len(tmp_data)), wavelet_freqs, np.log2(power), contourlevels, extend='both', cmap='jet')\n",
    "            plt.ylabel('Hz')\n",
    "            plt.xlabel('Time (seconds)')\n",
    "            plt.tight_layout()\n",
    "            #plt.savefig('cwt/%s_%s.png' % (record_name, channel), dpi=125)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        \"\"\"\n",
    "\n",
    "        #add to list\n",
    "        tmp_dict = {'window': tmp_win, 'label': tmp_labels, 'data': tmp_data, 'r': tmp_r}\n",
    "        windows.append(tmp_dict)\n",
    "    #print(len(windows))\n",
    "    return windows\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "faros = pd.read_pickle('./pickle/FAROS_preprocessed.pkl')\n",
    "#sot= pd.read_pickle('./pickle/SOT_preprocessed.pkl')\n",
    "#nex= pd.read_pickle('./pickle/NEXUS_preprocessed.pkl')\n",
    "#hex= pd.read_pickle('./pickle/HEXOSKIN_preprocessed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the actual data windowing on each channel separately. Then combine both channels and keep 90% for training, 10% for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import gc\n",
    "#window the data\n",
    "RATIO = 0.9\n",
    "\n",
    "train_sot,train_far,train_hex,train_nex= None,None,None,None\n",
    "test_sot,test_far,test_hex,test_nex= None,None,None,None\n",
    "#Faros\n",
    "windows_far = faros.apply(get_windows, activity='rest', axis=1)\n",
    "print(windows_far.shape)\n",
    "windows_far = pd.DataFrame(windows_far)\n",
    "print(windows_far.shape)\n",
    "windows_far = pd.DataFrame([item for sublist in windows_far.values for item in sublist[0]])\n",
    "print(windows_far.shape)\n",
    "train_far = windows_far.iloc[0:int(len(windows_far)*RATIO)]\n",
    "test_far = windows_far.iloc[int(len(windows_far)*RATIO)+1:]\n",
    "#free up memory\n",
    "faros = None\n",
    "windows_far = None\n",
    "gc.collect()\n",
    "\"\"\"\n",
    "#Sot\n",
    "windows_sot = sot.apply(get_windows, activity='raw', axis=1)\n",
    "windows_sot = pd.DataFrame(windows_sot)\n",
    "windows_sot = pd.DataFrame([item for sublist in windows_sot.values for item in sublist[0]])\n",
    "train_sot = windows_sot.iloc[0:int(len(windows_sot)*RATIO)]\n",
    "test_sot = windows_sot.iloc[int(len(windows_sot)*RATIO)+1:]\n",
    "\n",
    "#Nex\n",
    "windows_nex = nex.apply(get_windows, activity='raw', axis=1)\n",
    "windows_nex = pd.DataFrame(windows_nex)\n",
    "windows_nex = pd.DataFrame([item for sublist in windows_nex.values for item in sublist[0]])\n",
    "train_nex = windows_nex.iloc[0:int(len(windows_nex)*RATIO)]\n",
    "test_nex = windows_nex.iloc[int(len(windows_nex)*RATIO)+1:]\n",
    "\n",
    "#Hex\n",
    "windows_hex = hex.apply(get_windows, activity='raw', axis=1)\n",
    "windows_hex = pd.DataFrame(windows_hex)\n",
    "windows_hex = pd.DataFrame([item for sublist in windows_hex.values for item in sublist[0]])\n",
    "train_hex = windows_hex.iloc[0:int(len(windows_hex)*RATIO)]\n",
    "test_hex = windows_hex.iloc[int(len(windows_hex)*RATIO)+1:]\n",
    "\"\"\"\n",
    "\n",
    "#combine the all channels\n",
    "train = pd.concat((train_sot,train_far,train_hex,train_nex)).reset_index(drop=True)\n",
    "train.to_pickle('train.pkl', protocol=4)\n",
    "len_train=len(train)\n",
    "train=None\n",
    "gc.collect()\n",
    "test = pd.concat((test_sot,test_far,test_hex,test_nex)).reset_index(drop=True)\n",
    "test.to_pickle('test.pkl', protocol=4)\n",
    "len_test=len(test)\n",
    "test=None\n",
    "gc.collect()\n",
    "\n",
    "print('total number of windows: %i' % (len_train+len_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x011', 'x002', 'x001']\n",
      "total number of windows: 29874\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "#window the data\n",
    "RATIO = 0.9\n",
    "#从1-13中random选择3个数\n",
    "import random\n",
    "random.seed(42)\n",
    "channels = random.sample(range(1, 13), 3)\n",
    "#将3个数转换成x00n的形式\n",
    "channel_str = ['x00'+str(i) if i<10 else 'x0'+str(i) for i in channels]\n",
    "print(channel_str)\n",
    "\n",
    "train_sot,train_far,train_hex,train_nex= None,None,None,None\n",
    "test_sot,test_far,test_hex,test_nex= None,None,None,None\n",
    "\n",
    "continuous=False\n",
    "ACTIVITY='rest'\n",
    "\n",
    "\n",
    "#Faros\n",
    "if continuous:\n",
    "    windows_far = []\n",
    "    windows_far_test = []\n",
    "    for index,row in faros.iterrows():\n",
    "        #print(row)\n",
    "        temp = get_windows(row, activity=ACTIVITY)\n",
    "        #如果记录属于CHANELS中的一个\n",
    "        if index in channels:\n",
    "            #合并\n",
    "            windows_far_test.extend(temp)\n",
    "            #save the data\n",
    "            unit_test = pd.DataFrame(temp)\n",
    "            unit_test.to_pickle('test_%s.pkl' % channel_str[channels.index(index)], protocol=4)\n",
    "        else:\n",
    "            windows_far.extend(temp)\n",
    "\n",
    "    train_far = pd.DataFrame(windows_far)\n",
    "    test_far = pd.DataFrame(windows_far_test)\n",
    "    #free up memory\n",
    "    windows_far_raw, windows_far, windows_far_test = None, None, None\n",
    "    gc.collect()\n",
    "else:\n",
    "    windows_far_train = []\n",
    "    windows_far_test = []\n",
    "    for index,row in faros.iterrows():\n",
    "        temp=get_windows(row, activity=ACTIVITY)\n",
    "        #切分数据集+合并\n",
    "        pivot=int(len(temp)*RATIO)\n",
    "        windows_far_train.extend(temp[0:pivot])\n",
    "        windows_far_test.extend(temp[pivot:])\n",
    "    train_far = pd.DataFrame(windows_far_train)\n",
    "    test_far = pd.DataFrame(windows_far_test)\n",
    "\n",
    "#free up memory\n",
    "faros = None\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Sot\n",
    "windows_sot = sot.apply(get_windows, activity='raw', axis=1)\n",
    "windows_sot = pd.DataFrame(windows_sot)\n",
    "windows_sot = pd.DataFrame([item for sublist in windows_sot.values for item in sublist[0]])\n",
    "train_sot = windows_sot.iloc[0:int(len(windows_sot)*RATIO)]\n",
    "test_sot = windows_sot.iloc[int(len(windows_sot)*RATIO)+1:]\n",
    "\n",
    "#Nex\n",
    "windows_nex = nex.apply(get_windows, activity='raw', axis=1)\n",
    "windows_nex = pd.DataFrame(windows_nex)\n",
    "windows_nex = pd.DataFrame([item for sublist in windows_nex.values for item in sublist[0]])\n",
    "train_nex = windows_nex.iloc[0:int(len(windows_nex)*RATIO)]\n",
    "test_nex = windows_nex.iloc[int(len(windows_nex)*RATIO)+1:]\n",
    "\n",
    "#Hex\n",
    "windows_hex = hex.apply(get_windows, activity='raw', axis=1)\n",
    "windows_hex = pd.DataFrame(windows_hex)\n",
    "windows_hex = pd.DataFrame([item for sublist in windows_hex.values for item in sublist[0]])\n",
    "train_hex = windows_hex.iloc[0:int(len(windows_hex)*RATIO)]\n",
    "test_hex = windows_hex.iloc[int(len(windows_hex)*RATIO)+1:]\n",
    "\"\"\"\n",
    "\n",
    "#combine the all channels\n",
    "train = pd.concat((train_sot,train_far,train_hex,train_nex)).reset_index(drop=True)\n",
    "train.to_pickle('train.pkl', protocol=4)\n",
    "len_train=len(train)\n",
    "train=None\n",
    "gc.collect()\n",
    "test = pd.concat((test_sot,test_far,test_hex,test_nex)).reset_index(drop=True)\n",
    "test.to_pickle('test.pkl', protocol=4)\n",
    "len_test=len(test)\n",
    "test=None\n",
    "gc.collect()\n",
    "\n",
    "print('total number of windows: %i' % (len_train+len_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
